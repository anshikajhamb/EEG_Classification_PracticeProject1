# -*- coding: utf-8 -*-
"""EEGClassification_practice_project1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f41l3SvVnIrK9SSV1S-sSZLwwZjYVM8n
"""

!pip install mne
import glob 
import os 
import mne 
import numpy as np 
import pandas
import matplotlib.pyplot as plt 
from google.colab import drive
from google.colab import files

drive.mount('/content/gdrive')
!unzip gdrive/My\ Drive/dataverse_files.zip > /dev/null

os.chdir('/content')
file_list =[]
for file in glob.glob("*.edf"):
  file_list.append(file)


healthy_path = [file_list[i] for i in range(0,len(file_list)) if file_list[i].startswith('h')] 
schiz_path = [file_list[i] for i in range(0,len(file_list)) if file_list[i].startswith('s')]

def read_data(file_path):
  data = mne.io.read_raw_edf(file_path, preload=True)
  data.set_eeg_reference() # when we measure electrical activity from the scalp, we are measuring the electrical potential  
                            #at the location of the electrode, but it is necessarily relative to some other reference point. Applying avg reference here.  In this case, the average potential across all electrodes is subtracted from each individual electrode.
  data.filter(l_freq=0.5,h_freq=45) #Setting up band-pass filter from 0.5 - 45 Hz
  epochs = mne.make_fixed_length_epochs(data,duration=5,overlap=1) #Divide continuous raw data into equal-sized consecutive epochs.
  array = epochs.get_data() #Get all epochs as a 3D array.
  return array

sample_data = read_data(schiz_path[0])

print(sample_data.shape)

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# control_epochs_array = [read_data(i) for i in healthy_path]
# patient_epochs_array = [read_data(i) for i in schiz_path]

#the epochs of a subject may appearin both the training and test set, violating the independence between the training and test set
# therefore, subject-wise splitting of data is implemented. 

control_epoch_labels = [len(i)*[0] for i in control_epochs_array]
patient_epoch_labels = [len(i)*[1] for i in patient_epochs_array]

data_list = control_epochs_array+patient_epochs_array
label_list = control_epoch_labels+patient_epoch_labels

#creating distinct groups for each subject so that we can split training-test subject-wise
#here, each epoch from the same subject is given the same label
group_list = [[i]*len(j) for i,j in enumerate(data_list)]

#converting list to array
data_array = np.vstack(data_list)
label_array = np.hstack(label_list)
group_array = np.hstack(group_list)

print(len(data_list))
data_array.shape

#12 EEG features
from scipy import stats

def mean(x):
  return np.mean(x, axis=-1)

def std(x):
  return np.std(x, axis=-1)

def ptp(x):
  return np.ptp(x, axis=-1)

def var(x):
  return np.var(x, axis=-1)

def minim(x):
  return np.min(x, axis=-1)

def maxim(x):
  return np.max(x, axis=-1)

def argminim(x):
  return np.argmin(x, axis=-1)

def argmax(x):
  return np.argmax(x, axis=-1)

def rms(x):
  return np.sqrt(np.mean(x**2, axis=-1))

def abs_diff_signal(x):
  return np.sum(np.abs(np.diff(x,axis=-1)), axis=-1)

def skewness(x):
  return stats.skew(x, axis=-1)

def kurtosis(x):
  return stats.kurtosis(x, axis=-1)

def concatenate_features(x):
  return np.concatenate((mean(x), std(x), ptp(x), var(x), minim(x),maxim(x), argminim(x), argmax(x),rms(x), abs_diff_signal(x), skewness(x),  kurtosis(x)),axis=-1)

features =[]

for d in data_array:
  features.append(concatenate_features(d))

features_array = np.array(features)
features_array.shape

from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GroupKFold, GridSearchCV

clf = LogisticRegression()
gkf=GroupKFold(5)
pipe=Pipeline([('scalar', StandardScaler()), ('clf', clf)])
param_grid={'clf__C':[0.1,0.5,0.7,0.9,1,3,7,9,11]}
gscv=GridSearchCV(pipe, param_grid, cv=gkf,n_jobs=12)
gscv.fit(features_array, label_array, groups = group_array)

gscv.best_score_